# streamlit_app.py
import hashlib
import streamlit as st
import time
from pathlib import Path
import io
import requests
import threading
from typing import List, Dict
import json
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import re
import itertools
from openai import OpenAI
import os
import base64
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import openpyxl
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from matplotlib import rc
import matplotlib.font_manager as fm


# API í‚¤ ê¸°ë³¸ê°’ ì„¤ì •
llm_api_key = st.secrets["llm_api_key"]
naver_client_id = st.secrets["naver_client_id"]
naver_client_secret = st.secrets["naver_client_secret"]
xi_api_key = st.secrets["xi_api_key"]
voice_id = st.secrets["voice_id"]


st.set_page_config(
    initial_sidebar_state="collapsed",
    
)

# ì»¤ìŠ¤í…€ CSS ì¶”ê°€
st.markdown("""
    <style>
    @font-face {
        font-family: 'MaruBuBareun_hipiriBold';
         src: url('https://fastly.jsdelivr.net/gh/projectnoonnu/naverfont_01@1.0/Bareun_hipi.woff') format('woff');
        font-weight: bold;
        font-style: normal;
    }
    .custom-title {
        font-family: 'MaruBuBareun_hipiriBold', sans-serif;
        font-size: 3em; /* ì›í•˜ëŠ” í¬ê¸°ë¡œ ì¡°ì • */
        font-weight: bold;
    }
    .custom-title1 {
        font-family: 'MaruBuBareun_hipiriBold', sans-serif;
        font-size: 16px; /* ì›í•˜ëŠ” í¬ê¸°ë¡œ ì¡°ì • */
        font-weight: bold
        font-style: normal;
    }
    fixed-title {
        position: fixed;
        top: 5;
        width: 100%;
        z-index: 9999;
        padding: 8px;
    }
    </style>
    """, unsafe_allow_html=True)

# í˜ì´ì§€ ì œëª©
st.markdown('<h1 class="custom-title"> ì‹ í•œì¹´ë“œ ì‹ ì…ì‚¬ì› - CEO ì»¤ë®¤ë‹ˆì¼€ì´ì…˜  </h1>', unsafe_allow_html=True)
st.markdown('<h3 class="custom-title1"> ì‹ ì…ì‚¬ì›ë“¤ì€ ê¶ê¸ˆí•œ ì‚¬í•­ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš” ğŸ™‹â€â™€ï¸ğŸ™‹â€â™‚ï¸ </h3>', unsafe_allow_html=True)
    
class StreamlitNewsSearchSystem:
    def __init__(self, naver_client_id: str, naver_client_secret: str, llm_api_key: str, xi_api_key: str, voice_id: str):
        self.naver_client_id = naver_client_id
        self.naver_client_secret = naver_client_secret
        self.llm_api_key = llm_api_key
        self.xi_api_key = xi_api_key  # ElevenLabs API í‚¤
        self.voice_id = voice_id  # ElevenLabs Voice ID
        self.client = OpenAI(api_key=llm_api_key)
    
    def extract_keywords(self, query: str, progress_bar) -> List[str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            progress_bar.progress(10)
            st.write("ì •ë³´ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”")
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì‹ í•œì¹´ë“œ ë‹µë³€ ê´€ë ¨ ë´‡ì…ë‹ˆë‹¤. íšŒì‚¬ ê´€ë ¨ ë¬¸ì˜ë‚˜ ì§ˆë¬¸ì´ ë“¤ì–´ì™”ì„ ë•Œ, ì…ë ¥ëœ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í˜•íƒœë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": query
                    }
                ]
            )
            
            keywords = response.choices[0].message.content.split(',')
            keywords = [keyword.strip() for keyword in keywords]
            
            if 'ë¬¸ë™ê¶Œ' not in keywords:
                keywords.insert(0, 'ë¬¸ë™ê¶Œ')
            
            progress_bar.progress(20)
            return keywords
            
        except Exception as e:
            st.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e

    def clean_html_text(self, html_content: str) -> str:
        """HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ì œ"""
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.get_text(separator=' ', strip=True)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s\.,!?"\'-]', '', text)
        return text.strip()

    def get_full_article_content(self, url: str) -> str:
        """ê¸°ì‚¬ URLì—ì„œ ì „ì²´ ë‚´ìš© í¬ë¡¤ë§"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            if 'news.naver.com' in url:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')
                
                for selector in ['#articleBody', '#articleBodyContents', '#newsEndContents']:
                    article_content = soup.select_one(selector)
                    if article_content:
                        break
                        
            elif 'ceoscoredaily.com' in url:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')
                article_content = soup.select_one('.view_cont')
                
            if article_content:
                for unnecessary in article_content.select('script, style, header, footer'):
                    unnecessary.decompose()
                return self.clean_html_text(str(article_content))
                    
            return "ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            return "ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def search_naver_news(self, keywords: List[str], progress_bar, display: int = 5) -> List[Dict]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            query = ' '.join(keywords)
            url = "https://openapi.naver.com/v1/search/news.json"
            headers = {
                "X-Naver-Client-Id": self.naver_client_id,
                "X-Naver-Client-Secret": self.naver_client_secret
            }
            params = {
                "query": query,
                "display": display,
                "sort": "date"
            }
            
            progress_bar.progress(30)
            
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            news_items = response.json()['items']
            
            filtered_items = []
            with st.spinner("ê´€ë ¨ ê¸°ì‚¬ ë¶„ì„ ì¤‘..."):
                for item in news_items:
                    title = re.sub('<[^<]+?>', '', item['title'])
                    
                    shinhan_keywords = ['ì‹ í•œì¹´ë“œ', 'ë¬¸ë™ê¶Œ']
                    has_shinhan_keyword = any(keyword in title for keyword in shinhan_keywords)
                    
                    pub_date = datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900')
                    if pub_date.year >= 2023 and has_shinhan_keyword:
                        full_content = self.get_full_article_content(item['link'])
                        item['full_content'] = full_content
                        filtered_items.append(item)
            
            progress_bar.progress(40)
            return filtered_items
            
        except Exception as e:
            return []

    def search_with_progressive_keywords(self, keywords: List[str], progress_bar, display: int = 5) -> List[Dict]:
        """í‚¤ì›Œë“œë¥¼ ì ì§„ì ìœ¼ë¡œ ì¤„ì—¬ê°€ë©° ê²€ìƒ‰"""
        try:
            all_combinations = []
            other_keywords = [k for k in keywords if k != 'ë¬¸ë™ê¶Œ']
            
            # ê²€ìƒ‰ ì‹œì‘ ì•Œë¦¼
            with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
                for i in range(len(other_keywords), 0, -1):
                    for combo in itertools.combinations(other_keywords, i):
                        keywords_combo = ['ë¬¸ë™ê¶Œ'] + list(combo)
                        all_combinations.append(keywords_combo)
                    
                    for combo in all_combinations:
                        try:
                            news_items = self.search_naver_news(combo, progress_bar, display)
                            if news_items:
                                return news_items
                        except Exception as e:
                            continue
                
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ
                st.info("ê´€ë ¨ëœ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
                return []
                
        except Exception as e:
            st.error("ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return []

    def analyze_news_content(self, news_items: List[Dict], original_query: str, progress_bar) -> str:
        """ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„ ê°œì„  ë²„ì „"""
        try:
            st.write("ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„ ì¤‘...")
            progress_bar.progress(60)
            
            # ë‰´ìŠ¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° ì •ë¦¬
            news_metadata = []
            news_contents = []
            
            for item in news_items:
                # ë©”íƒ€ë°ì´í„°ì™€ ì½˜í…ì¸  ë¶„ë¦¬
                metadata = {
                    "title": item['title'],
                    "date": item['pubDate'],
                    "url": item['link']
                }
                news_metadata.append(metadata)
                
                # ì „ì²´ ì½˜í…ì¸ ëŠ” ë³„ë„ë¡œ ì €ì¥
                news_contents.append(item['full_content'])
            
            # í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ ê°•í™”
            system_prompt = """ë‹¹ì‹ ì€ ì‹ í•œì¹´ë“œì˜ CEOì™€ ì‹ ì…ì‚¬ì›ì˜ ì†Œí†µì„ ë•ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
            ì£¼ì–´ì§„ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
            1. ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
            2. ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ì˜ ì‹¤ì œ ë°œì–¸ì´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì¸ìš©í•©ë‹ˆë‹¤.
            3. ì‹¤ì œ ë°œì–¸ì´ ì—†ë‹¤ë©´ ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¼ê´€ëœ ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
            4. ì‹ í•œì¹´ë“œì˜ ì „ëµê³¼ ë°©í–¥ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤."""

            user_prompt = f"""ì›ë³¸ ì§ˆë¬¸: {original_query}

    ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©:
    {json.dumps(news_contents, ensure_ascii=False, indent=2)}

    ê¸°ì‚¬ ë©”íƒ€ë°ì´í„°:
    {json.dumps(news_metadata, ensure_ascii=False, indent=2)}

    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

    [ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€]
    (ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ 30ì´ˆ ë¶„ëŸ‰ì˜ ë‹µë³€)

    [ì°¸ê³  ê¸°ì‚¬]
    - ì œëª©: (ê´€ë ¨ì„± ë†’ì€ ìˆœì„œëŒ€ë¡œ)
    - ë‚ ì§œ: (ê¸°ì‚¬ ë‚ ì§œ)
    - URL: (ê¸°ì‚¬ ë§í¬)
    - ê´€ë ¨ ë‚´ìš©: (ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ë‚´ìš©)

    [ì‹ ì…ì‚¬ì› ê°€ì´ë“œ]
    (ì•ì„  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ì…ì‚¬ì›ë“¤ì´ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¼ì¸)"""

            progress_bar.progress(70)
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2
            )
            
            progress_bar.progress(80)
            return response.choices[0].message.content
            
        except Exception as e:
            st.error(f"ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e

    def extract_tts_content(self, text: str) -> str:
        """TTSìš© ì½˜í…ì¸  ì¶”ì¶œ"""
        try:
            if '[ì°¸ê³  ê¸°ì‚¬]' in text:
                text = text.split('[ì°¸ê³  ê¸°ì‚¬]')[0].strip()
            st.markdown(f"#### TTSìš© í…ìŠ¤íŠ¸:\n{text}")  # í…ìŠ¤íŠ¸ë¥¼ UIì— ì¶œë ¥
            return text
            
        except Exception as e:
            st.error(f"TTS ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return text
    @st.cache_data
    def generate_tts_with_elevenlabs(_self, text: str, xi_api_key: str, voice_id: str) -> str:
        """ElevenLabs APIë¥¼ í˜¸ì¶œí•˜ì—¬ TTS ìƒì„±"""
        try:
            # í…ìŠ¤íŠ¸ì˜ ê³ ìœ  í•´ì‹œê°’ ìƒì„± (ìºì‹± í‚¤ë¡œ í™œìš©)
            text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
            audio_file = f"output_{text_hash}.mp3"
            
            # ìºì‹œëœ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ í•´ë‹¹ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
            if Path(audio_file).exists():
                return audio_file
            
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": xi_api_key
            }
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.75,
                    "similarity_boost": 0.9,
                    "style": 0.2,
                    "use_speaker_boost": True,
                    "speaking_rate": 1.2
                     
                }
            }

            response = requests.post(url, json=data, headers=headers, stream=True)
            if response.status_code == 200:
                audio_file = "output.mp3"
                with open(audio_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                return audio_file
            else:
                st.error(f"ElevenLabs API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}, {response.text}")
                return None

        except Exception as e:
            st.error(f"ElevenLabs TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def speak_result(self, text: str) -> None:
        """Streamlitì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ìŒì„± ì¶œë ¥"""
        try:
            # [ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€] ì„¹ì…˜ë§Œ ì¶”ì¶œ
            if "[ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€]" in text:
                tts_content = text.split("[ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€]")[1].split("[ì°¸ê³  ê¸°ì‚¬]")[0].strip()
            else:
                return

            # TTS ìƒì„± í˜¸ì¶œ
            audio_path = self.generate_tts_with_elevenlabs(tts_content, self.xi_api_key, self.voice_id)

            if audio_path and Path(audio_path).exists():
                # Streamlitì„ í™œìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì¬ìƒ
                with open(audio_path, "rb") as audio_file:
                    audio_bytes = audio_file.read()
                    st.audio(audio_bytes, format="audio/mp3")
            else:
                st.error("ìŒì„± íŒŒì¼ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def save_message(message_content, role, message_type="chat"):
    """
    Save message to unified history with additional metadata
    message_type can be "chat" or "analysis"
    """
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    message_entry = {
        "message": message_content,  # ë©”ì‹œì§€ ë‚´ìš©
        "role": role,
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "type": message_type
    }
    st.session_state.messages.append(message_entry)


# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ assets í´ë” ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(SCRIPT_DIR, 'static')

def get_avatar_path(role: str) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ë°˜í™˜"""
    image_path = os.path.join(ASSETS_DIR, f'{role}_character.png')
    if os.path.exists(image_path):
        return image_path
    print(f"Warning: Image not found at {image_path}")  # ë””ë²„ê¹…ìš©
    return None

def send_message(message, role, save=True):
    """Display message with appropriate avatar"""
    avatar_path = get_avatar_path('human' if role == 'human' else 'bot')
    try:
        with st.chat_message(role, avatar=avatar_path):
            st.markdown(message, unsafe_allow_html=True)
        if save:  # ë©”ì‹œì§€ë¥¼ í•œ ë²ˆë§Œ ì €ì¥
            save_message(message, role)
    except Exception as e:
        print(f"Error displaying message with avatar: {e}")
        with st.chat_message(role):
            st.markdown(message, unsafe_allow_html=True)
        if save:
            save_message(message, role)

def get_image_as_base64(image_path):
    """ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode("utf-8")
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# ë°°ê²½ ì´ë¯¸ì§€ ì¶”ê°€
bg_image_path = "static/bg.png"  # ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ
if Path(bg_image_path).exists():
    bg_image_base64 = get_image_as_base64(bg_image_path)
    st.markdown(
        f"""
        <style>
        /* ì „ì²´ í˜ì´ì§€ ë°°ê²½ */
        html {{
            background-image: url("data:image/png;base64,{bg_image_base64}");
            background-size: cover;
            background-attachment: fixed;
            background-repeat: no-repeat;
        }}

        /* í…ìŠ¤íŠ¸ ì…ë ¥ì°½ í•˜ë‹¨ ì˜ì—­ (stChatInput) */
        [data-testid="stApp"]{{
            background-image: url("data:image/png;base64,{bg_image_base64}");
            background-size: cover;
    /       background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” *
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stSidebar"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stHeader"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stBottom"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stBottom"] > div {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        </style>
        """,
        unsafe_allow_html=True
    )
else:
    st.warning("ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def analyze_uploaded_file(file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¶”ì¶œ"""
    try:
        # íŒŒì¼ ì½ê¸° ì‹œë„
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        elif file.name.endswith('.xlsx'):
            df = pd.read_excel(file)
        else:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            return None, None

        # ë°ì´í„°í”„ë ˆì„ ì •ë³´ ì¶œë ¥
        st.write("### ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´")
        # í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
        text_columns = []
        for col in df.columns:
            # ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ì´ objectì´ê³  ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€
            if df[col].dtype == 'object' and df[col].str.len().mean() > 10:
                text_columns.append(col)

        if not text_columns:
            st.error("í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        # ì‚¬ìš©ìì—ê²Œ ë¶„ì„í•  ì»¬ëŸ¼ ì„ íƒ ì˜µì…˜ ì œê³µ
        selected_column = st.selectbox(
            "ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:",
            options=text_columns,
            help="ì§ˆë¬¸ ë‚´ìš©ì´ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )

        # ì „ì²´ í…ìŠ¤íŠ¸ ë°ì´í„° ê²°í•©
        text_data = '\n'.join(df[selected_column].dropna().astype(str))

        return text_data, df

    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        import traceback
        st.write("ìƒì„¸ ì˜¤ë¥˜:", traceback.format_exc())
        return None, None



def generate_wordcloud_from_keywords(keyword_data):
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (í•œê¸€ ì§€ì›)"""
    try:
        # í‚¤ì›Œë“œ ë°ì´í„° í™•ì¸
        if not keyword_data or not isinstance(keyword_data, list):
            st.error("ìœ íš¨í•œ í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì›Œë“œ í´ë¼ìš°ë“œ ì…ë ¥ ë°ì´í„° ìƒì„±
        wordcloud_input = {item["keyword"]: item["count"] for item in keyword_data if "keyword" in item and "count" in item}

        if not wordcloud_input:
            st.error("í‚¤ì›Œë“œ ë°ì´í„°ì— ë¹ˆë„ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # ë””ë²„ê¹…: ì…ë ¥ê°’ í™•ì¸
        st.write("ì›Œë“œí´ë¼ìš°ë“œ ë°ì´í„°:", wordcloud_input)

        # í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œ í°íŠ¸ ìë™ íƒìƒ‰)
        font_path = None
        for font in fm.findSystemFonts(fontpaths=None, fontext="ttf"):
            if "NanumGothic" in font or "Malgun" in font:  # í•œê¸€ ì§€ì› í°íŠ¸ ì°¾ê¸°
                font_path = font
                break

        if not font_path:
            st.error("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì— í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            return

        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color="white").generate_from_frequencies(wordcloud_input)
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation="bilinear")
        plt.axis("off")
        st.pyplot(plt)

    except Exception as e:
        st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")



def analyze_text(text_data, response_data=None):
    """í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ë¡œ ì‹œê°í™”"""
    # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ (í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œë¶€í„° ìƒì„±)
    if text_data:
        word_list = text_data.split()
        word_freq = pd.Series(word_list).value_counts().head(10)
        freq_df = pd.DataFrame({"keyword": word_freq.index, "count": word_freq.values})
    elif response_data and "keyword_frequency" in response_data:
        freq_df = pd.DataFrame(response_data["keyword_frequency"])
    else:
        st.error("í…ìŠ¤íŠ¸ ë°ì´í„° ë˜ëŠ” í‚¤ì›Œë“œ ë¹ˆë„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê°ì„± ë¶„ì„ ë°ì´í„°
    if response_data and "sentiment_analysis" in response_data:
        sentiment_data = response_data["sentiment_analysis"]
    else:
        sentiment_data = {"positive_score": 70, "negative_score": 20, "neutral_score": 10}

    total_score = sum(sentiment_data.values())
    normalized_score = (sentiment_data["positive_score"] / total_score) * 100

    # ì£¼ì œ ë¶„í¬ ë°ì´í„°
    if response_data and "topic_distribution" in response_data:
        topic_distribution = pd.DataFrame(response_data["topic_distribution"])
    else:
        topic_distribution = pd.DataFrame({
            "topic": ["ì£¼ì œ1", "ì£¼ì œ2", "ì£¼ì œ3"],
            "percentage": [40, 30, 30]
        })

    # ê²°ê³¼ ì‹œê°í™”
    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    st.markdown("#### ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
    generate_wordcloud_from_keywords(freq_df.to_dict("records"))

    # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸
    st.markdown("#### ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„")
    fig_freq = px.bar(freq_df, x="keyword", y="count", title="ì£¼ìš” í‚¤ì›Œë“œ Top 10")
    st.plotly_chart(fig_freq, use_container_width=True)
    
    # ê°ì„± ë¶„ì„ ê²Œì´ì§€
    st.markdown("#### ê°ì„± ë¶„ì„")
    fig_sentiment = go.Figure(go.Indicator(
        mode="gauge+number",
        value=normalized_score,
        title={'text': "ê¸ì •ë„ ì§€ìˆ˜"},
        gauge={
            'axis': {'range': [0, 100]},
            'steps': [
                {'range': [0, 50], 'color': "lightgray"},
                {'range': [50, 100], 'color': "lightblue"}
            ]
        }
    ))
    st.plotly_chart(fig_sentiment, use_container_width=True)
    
    # ì£¼ì œ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
    st.markdown("#### ì£¼ì œ ë¶„í¬")
    fig_topic = px.pie(topic_distribution, values="percentage", names="topic", title="ì£¼ì œ ë¶„í¬")
    st.plotly_chart(fig_topic, use_container_width=True)
    

def analyze_text_with_context(text_query: str, file_data: str, chat_history: list, search_system) -> dict:
    """íŒŒì¼ ë°ì´í„°ì™€ ì±„íŒ… ì´ë ¥ì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„ì„ ë˜ëŠ” ì¼ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        query_type = analyze_query_type(text_query, search_system.client)
        
        # íŒŒì¼ ë°ì´í„° ê¸¸ì´ ì œí•œ (ëª¨ë¸ì˜ í† í° ì œí•œ ê³ ë ¤)
        shortened_file_data = file_data[:2000]  # í•„ìš”ì— ë”°ë¼ ì¡°ì •

        # ì§ˆë¬¸ì—ì„œ ì›í•˜ëŠ” ë¶„ì„ ì¢…ë¥˜ íŒŒì•…
        requested_analysis = determine_requested_analysis(text_query)
        st.write("ìš”ì²­ëœ ë¶„ì„ ì¢…ë¥˜:", requested_analysis)

        # LLMì—ê²Œ ìš”ì²­í•  ë¶„ì„ ì¢…ë¥˜ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        analysis_instructions = ""
        if 'keyword_frequency' in requested_analysis:
            analysis_instructions += "1. í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ 'keyword_frequency' í‚¤ì— JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"
        if 'sentiment_analysis' in requested_analysis:
            analysis_instructions += "2. ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ 'sentiment_analysis' í‚¤ì— JSON ê°ì²´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"
        if 'topic_distribution' in requested_analysis:
            analysis_instructions += "3. ì£¼ì œ ë¶„í¬ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ 'topic_distribution' í‚¤ì— JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"

        if not analysis_instructions:
            analysis_instructions = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."

        # íŒŒì¼ ë°ì´í„°ë¥¼ í•­ìƒ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        analysis_prompt = f"""
        ì•„ë˜ì˜ íŒŒì¼ ë‚´ìš©ê³¼ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

        íŒŒì¼ ë‚´ìš©:
        {shortened_file_data}

        ì´ì „ ëŒ€í™”:
        {format_chat_history(chat_history)}

        ì‚¬ìš©ì ì§ˆë¬¸:
        {text_query}

        {analysis_instructions}
        """

        # LLM í˜¸ì¶œ
        response = search_system.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì´ì ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.7
        )

        raw_response = response.choices[0].message.content

        # ë°ì´í„° ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ ê²½ìš° JSON íŒŒì‹± ì‹œë„
        if query_type == 'data_analysis':
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            if json_match:
                json_content = json_match.group(0)
                try:
                    analysis_results = json.loads(json_content)
                except json.JSONDecodeError as e:
                    st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    analysis_results = None
                return {
                    "query_type": query_type,
                    "answer": raw_response,
                    "analysis": analysis_results
                }
            else:
                # JSONì´ ì—†ì„ ê²½ìš°ì—ë„ 'analysis' í‚¤ë¥¼ í¬í•¨
                return {
                    "query_type": query_type,
                    "answer": raw_response,
                    "analysis": None  # ë˜ëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬ {}
                }
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜
            return {
                "query_type": query_type,
                "answer": raw_response
            }

    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None



def analyze_query_type(query: str, client) -> str:
    """ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ìœ í˜•ì„ ë¶„ì„í•˜ì—¬ 'data_analysis' ë˜ëŠ” 'text_query'ë¡œ ë¶„ë¥˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ 'data_analysis' ë˜ëŠ” 'text_query' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì´ ë°ì´í„° íŒŒì¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©´ 'data_analysis'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ì§ˆë¬¸: '{query}'\n\nì§ˆë¬¸ì˜ ìœ í˜•ì„ 'data_analysis' ë˜ëŠ” 'text_query'ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."}
            ],
            temperature=0
        )
        result = response.choices[0].message.content.strip().lower()
        if 'data_analysis' in result:
            return 'data_analysis'
        else:
            return 'text_query'
    except Exception:
        return 'text_query'  # ê¸°ë³¸ê°’ìœ¼ë¡œ 'text_query' ë°˜í™˜


        
# ì‚¬ì´ë“œë°”ì—ì„œ í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ëª¨ë“œ ì¶”ê°€
def create_sidebar_with_text_analysis():
    """ì‚¬ì´ë“œë°”ì—ì„œ í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ëª¨ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    with st.sidebar:
        st.markdown("### ğŸ¤– ì±—ë´‡ ëª¨ë“œ ì„ íƒ")
        
        # ëª¨ë“œ ì„ íƒ
        mode = st.radio(
            "ì›í•˜ì‹œëŠ” ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            ["ê¸°ë³¸ ì±—ë´‡", "í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡"],
            index=0,
            key="chat_mode_sidebar"  # ê³ ìœ  í‚¤ë¡œ ë³€ê²½
        )
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.analysis_mode = (mode == "í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡")


def format_analysis_results(analysis_results):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥í•˜ê¸° ìœ„í•œ í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    formatted_result = "### ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼\n\n"
    
    # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ í¬ë§·íŒ…
    if 'keyword_frequency' in analysis_results:
        formatted_result += "#### ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„\n"
        for keyword in analysis_results['keyword_frequency']:
            formatted_result += f"- {keyword['keyword']}: {keyword['count']}íšŒ\n"
        formatted_result += "\n"
    
    # ì£¼ì œ ë¶„í¬ í¬ë§·íŒ…
    if 'topic_distribution' in analysis_results:
        formatted_result += "#### ì£¼ì œ ë¶„í¬\n"
        for topic in analysis_results['topic_distribution']:
            formatted_result += f"- {topic['topic']}: {topic['percentage']}%\n"
        formatted_result += "\n"
    
    # ê°ì„± ë¶„ì„ í¬ë§·íŒ…
    if 'sentiment_analysis' in analysis_results:
        sentiment = analysis_results['sentiment_analysis']
        total_score = sum(sentiment.values())
        formatted_result += "#### ê°ì„± ë¶„ì„\n"
        formatted_result += f"- ê¸ì •: {(sentiment['positive_score']/total_score)*100:.1f}%\n"
        formatted_result += f"- ë¶€ì •: {(sentiment['negative_score']/total_score)*100:.1f}%\n"
        formatted_result += f"- ì¤‘ë¦½: {(sentiment['neutral_score']/total_score)*100:.1f}%\n\n"
    
    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ í¬ë§·íŒ…
    if 'key_insights' in analysis_results:
        formatted_result += "#### ì£¼ìš” ì¸ì‚¬ì´íŠ¸\n"
        for insight in analysis_results['key_insights']:
            formatted_result += f"- {insight}\n"
    
    return formatted_result

def save_analysis_to_history(st_state, analysis_results, uploaded_filename):
    """ë¶„ì„ ê²°ê³¼ì™€ ì°¨íŠ¸ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì €ì¥
    analysis_entry = {
        'timestamp': timestamp,
        'filename': uploaded_filename,
        'results': analysis_results,
        'type': 'analysis'  # ë©”ì‹œì§€ íƒ€ì…ì„ ë¶„ì„ìœ¼ë¡œ í‘œì‹œ
    }
    
    # ëŒ€í™” ì´ë ¥ì— ì €ì¥
    if 'messages' not in st_state:
        st_state.messages = []
    st_state.messages.append({
        "message": analysis_entry,
        "role": "ai",
        "type": "analysis"  # ë¶„ì„ íƒ€ì… ë©”ì‹œì§€ì„ì„ í‘œì‹œ
    })
    
    # ê²€ìƒ‰ ì´ë ¥ì—ë„ ì €ì¥
    if 'search_history' not in st_state:
        st_state.search_history = []
    st_state.search_history.append(analysis_entry)


def display_analysis_results(analysis_results, requested_analysis=None):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì°¨íŠ¸ì™€ í•¨ê»˜ í‘œì‹œ"""
    if requested_analysis is None:
        requested_analysis = ['keyword_frequency', 'sentiment_analysis', 'topic_distribution']
    try:
        st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")

        # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ë¶„ì„
        if 'keyword_frequency' in requested_analysis and 'keyword_frequency' in analysis_results and analysis_results['keyword_frequency']:
            st.markdown("#### ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„")
            keyword_data = analysis_results['keyword_frequency']
            if isinstance(keyword_data, list) and len(keyword_data) > 0:
                # 'frequency' í‚¤ë¥¼ 'count' í‚¤ë¡œ ë³€ê²½
                for item in keyword_data:
                    if 'frequency' in item:
                        item['count'] = item.pop('frequency')
                keyword_df = pd.DataFrame(keyword_data)
                # ì°¨íŠ¸ ìƒì„±
                try:
                    fig_freq = px.bar(keyword_df, x='keyword', y='count', title="ì£¼ìš” í‚¤ì›Œë“œ Top 10", labels={'count': 'ë¹ˆë„ìˆ˜', 'keyword': 'í‚¤ì›Œë“œ'})
                    st.plotly_chart(fig_freq, use_container_width=True)
                except Exception as e:
                    st.error("í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    print(f"í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    print("í‚¤ì›Œë“œ ë°ì´í„°:", keyword_df)

        # ê°ì„± ë¶„ì„
        if 'sentiment_analysis' in requested_analysis and 'sentiment_analysis' in analysis_results:
            st.markdown("#### ê°ì„± ë¶„ì„")
            try:
                sentiment = analysis_results['sentiment_analysis']
                total_score = sum(sentiment.values())
                if total_score > 0:
                    positive_ratio = (sentiment.get('positive_score', 0) / total_score) * 100
                    fig_sentiment = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=positive_ratio,
                        title={'text': "ê¸ì •ë„ ë¹„ìœ¨"},
                        gauge={
                            'axis': {'range': [0, 100]},
                            'steps': [
                                {'range': [0, 50], 'color': "lightgray"},
                                {'range': [50, 100], 'color': "lightblue"}
                            ]
                        }
                    ))
                    st.plotly_chart(fig_sentiment, use_container_width=True)
                else:
                    st.error("ê°ì„± ë¶„ì„ ê²°ê³¼ì˜ ì´ ì ìˆ˜ê°€ 0ì…ë‹ˆë‹¤.")
            except Exception as e:
                st.error("ê°ì„± ë¶„ì„ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                print(f"ê°ì„± ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                print("ê°ì„± ë¶„ì„ ë°ì´í„°:", sentiment)

        # ì£¼ì œ ë¶„í¬ ë¶„ì„
        if 'topic_distribution' in requested_analysis and 'topic_distribution' in analysis_results and analysis_results['topic_distribution']:
            st.markdown("#### ì£¼ì œ ë¶„í¬")
            try:
                topic_data = analysis_results['topic_distribution']
                if isinstance(topic_data, list) and len(topic_data) > 0:
                    # 'frequency' ë˜ëŠ” 'count' í‚¤ë¥¼ 'count'ë¡œ í†µì¼
                    for item in topic_data:
                        if 'frequency' in item:
                            item['count'] = item.pop('frequency')
                    topic_df = pd.DataFrame(topic_data)
                    # 'percentage' ê³„ì‚°
                    if 'count' in topic_df.columns:
                        total_count = topic_df['count'].sum()
                        topic_df['percentage'] = (topic_df['count'] / total_count) * 100
                    else:
                        st.error("ì£¼ì œ ë¶„í¬ ë°ì´í„°ì— 'count' ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                        return
                    # ì°¨íŠ¸ ìƒì„±
                    if not topic_df.empty and 'topic' in topic_df.columns and 'percentage' in topic_df.columns:
                        fig_topic = px.pie(topic_df, values='percentage', names='topic', title="ì£¼ì œë³„ ë¶„í¬")
                        st.plotly_chart(fig_topic, use_container_width=True)
                    else:
                        st.error("ì£¼ì œ ë¶„í¬ ë°ì´í„°ì— í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.error("ì£¼ì œ ë¶„í¬ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error("ì£¼ì œ ë¶„í¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                print(f"ì£¼ì œ ë¶„í¬ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                print("ì£¼ì œ ë¶„í¬ ë°ì´í„°:", topic_df)

        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ í‘œì‹œ (í•„ìš” ì‹œ)
        if 'key_insights' in analysis_results:
            st.markdown("#### ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            insights = analysis_results['key_insights']
            if isinstance(insights, list):
                for insight in insights:
                    st.markdown(f"- {insight}")

    except Exception as e:
        st.error("ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ë¶„ì„ ê²°ê³¼ ë°ì´í„°:", analysis_results)



def format_chat_history(history):
    """ì±„íŒ… ì´ë ¥ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    formatted = []
    for item in history:
        if isinstance(item, dict):
            role = item.get('role', '')
            message = item.get('message', '')
            formatted.append(f"{role}: {message}")
    return "\n".join(formatted)


def display_combined_analysis(result):
    if not result:
        return

    # ë‹µë³€ í‘œì‹œ
    st.markdown("### ğŸ’¬ ë‹µë³€")
    st.markdown(result.get("answer", ""))

    # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì°¨íŠ¸ í‘œì‹œ
    if result.get("query_type") == "data_analysis" and "analysis" in result:
        st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
        analysis_results = result["analysis"]

        # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸
        if 'keyword_frequency' in analysis_results:
            st.markdown("#### ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„")
            keyword_df = pd.DataFrame(analysis_results['keyword_frequency'])
            fig = px.bar(keyword_df, x="keyword", y="count", 
                        title="í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜",
                        labels={"count": "ì¶œí˜„ íšŸìˆ˜", "keyword": "í‚¤ì›Œë“œ"})
            st.plotly_chart(fig, use_container_width=True)
        
        # ì£¼ì œ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        if 'topic_distribution' in analysis_results:
            st.markdown("#### ì£¼ì œ ë¶„í¬")
            topic_df = pd.DataFrame(analysis_results['topic_distribution'])
            fig = px.pie(topic_df, values="percentage", names="topic", 
                        title="ì£¼ì œë³„ ë¶„í¬")
            st.plotly_chart(fig, use_container_width=True)
        
        # ê°ì„± ë¶„ì„ ê²Œì´ì§€
        if 'sentiment_analysis' in analysis_results:
            st.markdown("#### ê°ì„± ë¶„ì„")
            sentiment = analysis_results['sentiment_analysis']
            total_score = sum(sentiment.values())
            positive_ratio = (sentiment["positive_score"] / total_score) * 100
            
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=positive_ratio,
                title={'text': "ê¸ì •ë„ ë¹„ìœ¨"},
                gauge={
                    'axis': {'range': [0, 100]},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 100], 'color': "lightblue"}
                    ]
                }
            ))
            st.plotly_chart(fig, use_container_width=True)
        
        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
        if 'key_insights' in analysis_results:
            st.markdown("#### ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            for insight in analysis_results['key_insights']:
                st.markdown(f"- {insight}")


def main_analysis_chat():
    """í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ë©”ì¸ í•¨ìˆ˜"""
    st.markdown("### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ë¶„ì„í•  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV ë˜ëŠ” XLSX)", 
                                   type=["csv", "xlsx"])
    
    # íŒŒì¼ ì—…ë¡œë“œ ë° ì´ˆê¸° ë¶„ì„
    if uploaded_file and "file_data" not in st.session_state:
        file_analysis_result = analyze_uploaded_file(uploaded_file)
        if file_analysis_result:
            text_data, df = file_analysis_result
            st.session_state.file_data = text_data
            st.session_state.file_df = df
            st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if st.session_state.analysis_mode and "file_data" in st.session_state:
        # í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ëª¨ë“œ
        query = st.chat_input("ë¶„ì„ ëª¨ë“œì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="analysis_input")
        if query:
            st.session_state.analysis_history.append({"role": "user", "content": query})
            send_message(query, "human")  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = analyze_text_with_context(
                    text_query=query,
                    file_data=st.session_state.file_data,
                    chat_history=st.session_state.messages,
                    search_system=st.session_state.search_system,
                )
                with st.chat_message("ai", avatar="static/bot_character.png"):
                    display_combined_analysis(result)
                save_message(result.get("answer", ""), "ai")  # ë¶„ì„ ê²°ê³¼ ì €ì¥

        # ì…ë ¥ê°’ ì²˜ë¦¬
        if query:
            save_message(query, "user")  # íˆìŠ¤í† ë¦¬ ì €ì¥ ìë™í™”
            send_message(query, "human")  # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ

            # ëª¨ë“œë³„ ì²˜ë¦¬
            if st.session_state.analysis_mode:
                main_analysis_chat()  # ë¶„ì„ ëª¨ë“œ
            else:
                process_regular_chat(query, progress_bar=None)  # ì¼ë°˜ ëª¨ë“œ


            
            # ë¶„ì„ ìˆ˜í–‰
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = analyze_text_with_context(
                    text_query=query,
                    file_data=st.session_state.file_data,
                    chat_history=st.session_state.messages,
                    search_system=st.session_state.search_system
                )
                
                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                with st.chat_message("ai", avatar="static/bot_character.png"):
                    display_combined_analysis(result)
                
                # ëŒ€í™” ì´ë ¥ ì €ì¥
                save_message(result.get("answer", ""), "ai")
    else:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            

# Initialize session state with unified history
def initialize_session_state():
    if 'initialized' not in st.session_state:
        st.session_state.messages = []  # Unified message history
        st.session_state.search_history = []  # Unified search history
        st.session_state.file_data = None
        st.session_state.file_df = None
        st.session_state.tts_enabled = True
        st.session_state.audio_played = False
        st.session_state.query = None  # query ì´ˆê¸°í™” ì¶”ê°€
        st.session_state.search_system = StreamlitNewsSearchSystem(
            naver_client_id=naver_client_id,
            naver_client_secret=naver_client_secret,
            llm_api_key=llm_api_key,
            xi_api_key=xi_api_key,
            voice_id=voice_id
        )
        st.session_state.analysis_mode = False
        st.session_state.initialized = True

# ì´ˆê¸°í™” í•¨ìˆ˜ë¥¼ ìŠ¤í¬ë¦½íŠ¸ ì´ˆê¸°ì— ì‹¤í–‰
initialize_session_state()
    
        
# ìºë¦­í„° ì´ë¯¸ì§€ ê²½ë¡œ
user_img = "static/human_character.png"  # ì‚¬ìš©ì ìºë¦­í„° ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
bot_img = "static/bot_character.png"  # ì±—ë´‡ ìºë¦­í„° ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

if not Path(user_img).exists():
    raise FileNotFoundError(f"File not found: {user_img}")

# ë©”ì‹œì§€ë¥¼ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def send_message_with_image(message, role, image_path, save=True):
    """ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ì—¬ ë©”ì‹œì§€ë¥¼ í‘œì‹œ"""
    message_html = f"""
    <div style="display: flex; align-items: flex-start; margin-bottom: 10px;">
        <img src="{image_path}" alt="{role}" style="width: 50px; height: 50px; margin-right: 10px; border-radius: 50%;">
        <div style="background-color: #f1f1f1; padding: 10px; border-radius: 10px; max-width: 80%;">
            {message}
        </div>
    </div>
    """
    st.markdown(message_html, unsafe_allow_html=True)
    if save:
        save_message(message, role)

# ë©”ì‹œì§€ ê¸°ë¡ í‘œì‹œ í•¨ìˆ˜
def paint_history():
    """ëŒ€í™” ì´ë ¥ í‘œì‹œ"""
    if "messages" in st.session_state:
        for message in st.session_state.messages:
            if isinstance(message, dict):
                role = message.get("role", "")
                content = message.get("message", "")
                
                # ë©”ì‹œì§€ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
                if message.get("type") == "analysis":
                    # st.chat_message ë‚´ë¶€ì—ì„œëŠ” í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë§Œ í‘œì‹œ
                    if isinstance(content, dict):
                        # ë‹µë³€ í…ìŠ¤íŠ¸ í‘œì‹œ
                        if "answer" in content and content["answer"]:
                            send_message(content["answer"], role, save=False)
                        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ (st.chat_message ë°”ê¹¥ì—ì„œ)
                        if "analysis" in content and content["analysis"]:
                            # ì´ì „ì— ìš”ì²­ëœ ë¶„ì„ ì¢…ë¥˜ë¥¼ ë³µì›í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì„¤ì •
                            requested_analysis = determine_requested_analysis(content.get("answer", ""))
                            display_analysis_results(content["analysis"], requested_analysis)
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë©”ì‹œì§€ í‘œì‹œ
                        send_message(content, role, save=False)
                else:
                    # ì¼ë°˜ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
                    send_message(content, role, save=False)



def extract_section(text, start_marker, end_marker=None):
    """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì„¹ì…˜ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        if start_marker not in text:
            return None
        
        parts = text.split(start_marker, 1)
        if len(parts) < 2:
            return None
            
        content = parts[1]
        
        if end_marker:
            if end_marker in content:
                content = content.split(end_marker)[0]
        
        return content.strip()
    except Exception:
        return None
    

def process_regular_chat(query, progress_bar):
    """ê¸°ì¡´ ì±—ë´‡ ëª¨ë“œ ì²˜ë¦¬"""
    try:
        if 'audio_played' in st.session_state:
            del st.session_state.audio_played
            
        keywords = st.session_state.search_system.extract_keywords(query, progress_bar)
        news_items = st.session_state.search_system.search_with_progressive_keywords(
            keywords, progress_bar
        )
        
        if not news_items:
            alt_response = st.session_state.search_system.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹ í•œì¹´ë“œì˜ CEO ë¬¸ë™ê¶Œ ì‚¬ì¥ì…ë‹ˆë‹¤..."},
                    {"role": "user", "content": query}
                ],
                temperature=0.7
            ).choices[0].message.content

            st.markdown(f"#### ğŸ’¬ AIë‹µë³€\n{alt_response}")
            save_message(alt_response, "ai")
            st.session_state.search_history.append({
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'query': query,
                'result': f"ğŸ’¬ AIë‹µë³€: {alt_response}"
            })
            return

        result = st.session_state.search_system.analyze_news_content(
            news_items, query, progress_bar
        )
        
        if result:
            st.session_state.current_result = result
            st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
            
            # ê° ì„¹ì…˜ ì¶”ì¶œ
            speech_part = extract_section(result, "[ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€]", "[ì°¸ê³  ê¸°ì‚¬]")
            ref_part = extract_section(result, "[ì°¸ê³  ê¸°ì‚¬]", "[ì‹ ì…ì‚¬ì› ê°€ì´ë“œ]")
            guide_part = extract_section(result, "[ì‹ ì…ì‚¬ì› ê°€ì´ë“œ]")
            
            # ê²°ê³¼ ì»¨í…Œì´ë„ˆ
            with st.container():
                if ref_part:
                    st.markdown("#### ğŸ“° ì°¸ê³  ê¸°ì‚¬")
                    lines = ref_part.split('\n')
                    formatted_lines = []
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                        if "URL:" in line:
                            url_parts = line.split("URL:")
                            if len(url_parts) > 1:
                                url = url_parts[1].strip()
                                formatted_lines.append(f"- URL: <a href='{url}' target='_blank'>{url}</a>")
                        else:
                            formatted_lines.append(f"- {line}")
                    formatted_ref = '<br>'.join(formatted_lines)
                    st.markdown(formatted_ref, unsafe_allow_html=True)
                
                if guide_part:
                    st.markdown("#### ğŸ¯ ì‹ ì…ì‚¬ì› ê°€ì´ë“œ")
                    st.markdown(f"""
                    <div style='background-color: #e8f4f9; padding: 20px; border-radius: 10px;'>
                        {guide_part}
                    </div>
                    """, unsafe_allow_html=True)
                
                if speech_part:
                    st.markdown(f"""
                    <div style="display: flex; align-items: center; margin-bottom: 10px;">
                        <img src="data:image/png;base64,{get_image_as_base64('static/bot_character.png')}" 
                            alt="Bot Icon" 
                            style="width: 30px; height: 30px; margin-right: 10px; border-radius: 50%;">
                        <h3 style="margin: 0; display: inline;">AIë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€</h3>
                    </div>
                    <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px;">
                        {speech_part}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if st.session_state.tts_enabled and 'audio_played' not in st.session_state:
                        st.session_state.search_system.speak_result(result)
                        st.session_state.audio_played = True
            
            # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
            formatted_result = f"""### ğŸ“Š ë¶„ì„ ê²°ê³¼\n\n"""
            if ref_part:
                formatted_result += f"""#### ğŸ“° ì°¸ê³  ê¸°ì‚¬\n{formatted_ref}\n\n"""
            if guide_part:
                formatted_result += f"""#### ğŸ¯ ì‹ ì…ì‚¬ì› ê°€ì´ë“œ\n{guide_part}\n\n"""
            if speech_part:
                formatted_result += f"""#### ğŸ’¬ ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€\n{speech_part}"""
            
            # ëŒ€í™” ì´ë ¥ì— í•œ ë²ˆë§Œ ì €ì¥
            st.session_state.search_history.append({
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'query': query,
                'result': formatted_result
            })
            save_message(formatted_result, "ai")
            return formatted_result
            
    except Exception as e:
        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


def display_bot_section_with_image(title, bot_image_path, content):
    """ì•„ì´ì½˜ ëŒ€ì‹  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ì„ í‘œì‹œ"""
    st.markdown(f"""
    <div style="display: flex; align-items: center; margin-bottom: 10px;">
        <img src="{bot_image_path}" alt="Bot Icon" style="width: 30px; height: 30px; margin-right: 10px; border-radius: 50%;">
        <h3 style="margin: 0; display: inline;">{title}</h3>
    </div>
    <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px;Æ’">
        {content}
    </div>
    """, unsafe_allow_html=True)

    if uploaded_file:
        file_analysis_result = analyze_uploaded_file(uploaded_file)
        if file_analysis_result:  # ìœ íš¨í•œ íŒŒì¼ë§Œ ì²˜ë¦¬
            text_data, df = file_analysis_result
            st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ë¶„ì„ ë²„íŠ¼ ì¶”ê°€
            if st.button("ë¶„ì„ ì‹œì‘"):
                with st.spinner("LLMì„ í†µí•´ ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                    # LLMì— í…ìŠ¤íŠ¸ ë°ì´í„° ì „ë‹¬
                    llm_prompt = f"""
                    ì•„ë˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ **JSONìœ¼ë¡œë§Œ** ë°˜í™˜í•˜ì„¸ìš”. 
                    JSON ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë°˜í™˜ ê°’ì€ ë¬¸ìì—´ì´ ì•„ë‹ˆë©° JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

                    ë°ì´í„°:
                    {text_data[:1000]} 
                    
                    ë¶„ì„ ìš”êµ¬ì‚¬í•­:
                    1. í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ë¶„ì„: "keyword_frequency"ì— JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.
                    2. ì£¼ì œ ë¶„í¬: "topic_distribution"ì— JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.
                    3. ê°ì„± ë¶„ì„: "sentiment_analysis"ì— JSON ê°ì²´ë¡œ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ë¹„ìœ¨ì„ ë°˜í™˜í•˜ì„¸ìš”.
                    4. ì£¼ìš” ì¸ì‚¬ì´íŠ¸: ì§ˆë¬¸ì—ì„œ ì˜ê°ì„ ì–»ì„ë§Œí•œ ê²ƒë“¤ì„ "key_insights"ì— JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

                    JSON í˜•ì‹ ì˜ˆ:
                    {{
                        "keyword_frequency": [
                            {{"keyword": "example", "count": 10}},
                            ...
                        ],
                        "topic_distribution": [
                            {{"topic": "example_topic", "percentage": 50}},
                            ...
                        ],
                        "sentiment_analysis": {{
                            "positive_score": 60,
                            "negative_score": 30,
                            "neutral_score": 10
                        }},
                        "key_insights": [
                            "Insight 1",
                            "Insight 2"
                        ]
                    }}
"""
                    try:
                        response = st.session_state.search_system.client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                                {"role": "user", "content": llm_prompt}
                            ],
                            temperature=0.2
                        )
                        

                        # LLM ì‘ë‹µ ì²˜ë¦¬
                        raw_response = response.choices[0].message.content
                        analysis_results = json.loads(raw_response)

                        # ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ
                        st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
                        # ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        display_analysis_results(analysis_results, uploaded_file.name)
                        
                        # ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥
                        save_analysis_to_history(
                            st_state=st.session_state,
                            analysis_results=analysis_results,
                            uploaded_filename=uploaded_file.name
                        )
                    
                        # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€
                        st.success("ë¶„ì„ ê²°ê³¼ê°€ ëŒ€í™” ì´ë ¥ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                    except json.JSONDecodeError as e:
                        st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        st.write("LLM ì‘ë‹µ ë‚´ìš©:", response.choices[0].message.content)
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

                        # ê²°ê³¼ ì‹œê°í™”
                        st.markdown("### ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼")

                        # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜
                        st.markdown("#### ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„")
                        keyword_df = pd.DataFrame(analysis_results['keyword_frequency'])
                        keyword_chart = px.bar(keyword_df, x="keyword", y="count", title="í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜")
                        st.plotly_chart(keyword_chart, use_container_width=True)

                        # ì£¼ì œ ë¶„í¬
                        st.markdown("#### ì£¼ì œ ë¶„í¬")
                        topic_df = pd.DataFrame(analysis_results['topic_distribution'])
                        topic_chart = px.pie(topic_df, values="percentage", names="topic", title="ì£¼ì œ ë¶„í¬")
                        st.plotly_chart(topic_chart, use_container_width=True)

                        # ê°ì„± ë¶„ì„
                        st.markdown("#### ê°ì„± ë¶„ì„")
                        sentiment = analysis_results['sentiment_analysis']
                        total_score = sum(sentiment.values())
                        positive_ratio = (sentiment["positive_score"] / total_score) * 100

                        sentiment_chart = go.Figure(go.Indicator(
                            mode="gauge+number",
                            value=positive_ratio,
                            title={'text': "ê¸ì •ë„ ë¹„ìœ¨"},
                            gauge={
                                'axis': {'range': [0, 100]},
                                'steps': [
                                    {'range': [0, 50], 'color': "lightgray"},
                                    {'range': [50, 100], 'color': "lightblue"}
                                ]
                            }
                        ))
                        st.plotly_chart(sentiment_chart, use_container_width=True)

                        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
                        st.markdown("#### ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
                        for insight in analysis_results['key_insights']:
                            st.markdown(f"- {insight}")

                    except Exception as e:  # ì´ ì¤„ì˜ ë“¤ì—¬ì“°ê¸°ê°€ ë§ì§€ ì•Šì•„ ì˜¤ë¥˜ ë°œìƒ
                        st.error(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        else:
            st.error("íŒŒì¼ì„ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í›„ì— ì‚¬ì´ë“œë°” ì¶”ê°€
with st.sidebar:
    # ì‚¬ìš© ê°€ì´ë“œ
    st.markdown("### ğŸ¯ ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    1. íšŒì‚¬ì— ë¬¸ì˜í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”
    2. ê²€ìƒ‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    3. ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë˜ë©° ìŒì„±ìœ¼ë¡œë„ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)
    
    st.markdown("---")
    
    # ê²€ìƒ‰ ê¸°ë¡
    if st.session_state.search_history:
        st.markdown(f"ì´ ê²€ìƒ‰ íšŸìˆ˜: {len(st.session_state.search_history)}íšŒ")

def process_query(query, progress_bar):
    """
    ì‚¬ìš©ì ì…ë ¥(query)ì„ ì²˜ë¦¬í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ, ë‰´ìŠ¤ ê²€ìƒ‰, ê²°ê³¼ ë¶„ì„ ë° í‘œì‹œ.
    """
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = st.session_state.search_system.extract_keywords(query, progress_bar)

    # ë‰´ìŠ¤ ê²€ìƒ‰
    news_items = st.session_state.search_system.search_with_progressive_keywords(
        keywords, progress_bar
    )

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if not news_items:
        handle_no_results(query)
        return

    # ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„
    result = st.session_state.search_system.analyze_news_content(
        news_items, query, progress_bar
    )

    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if result:
        display_analysis_results(result)

def handle_no_results(query):
    """ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œì˜ ì²˜ë¦¬"""
    try:
        response = st.session_state.search_system.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹ í•œì¹´ë“œì˜ CEO ë¬¸ë™ê¶Œ ì‚¬ì¥ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": query}
            ],
            temperature=0.4
        )
        
        alt_response = response.choices[0].message.content
        st.markdown(f"#### ğŸ’¬ AIë‹µë³€\n{alt_response}")
        
        # ê²€ìƒ‰ ì´ë ¥ì— ì €ì¥
        st.session_state.search_history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'query': query,
            'result': f"ğŸ’¬ AIë‹µë³€: {alt_response}"
        })
        
        return alt_response
        
    except Exception as e:
        st.error(f"ëŒ€ì²´ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_analysis_sections(result):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ UIì— í‘œì‹œ.
    """
    # ì„¹ì…˜ ì¶”ì¶œ
    speech_part = extract_section(result, "[ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€]", "[ì°¸ê³  ê¸°ì‚¬]")
    ref_part = extract_section(result, "[ì°¸ê³  ê¸°ì‚¬]", "[ì‹ ì…ì‚¬ì› ê°€ì´ë“œ]")
    guide_part = extract_section(result, "[ì‹ ì…ì‚¬ì› ê°€ì´ë“œ]")

    # ì°¸ê³  ê¸°ì‚¬ ì„¹ì…˜
    if ref_part:
        display_reference_section(ref_part)

    # ê°€ì´ë“œ ì„¹ì…˜
    if guide_part:
        display_guide_section(guide_part)

    # ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€
    if speech_part:
        display_speech_section(speech_part)

    # ê²°ê³¼ ì €ì¥
    save_analysis_result(result, ref_part, guide_part, speech_part)

def display_reference_section(ref_part):
    """
    ì°¸ê³  ê¸°ì‚¬ ì„¹ì…˜ í‘œì‹œ.
    """
    st.markdown("#### ğŸ“° ì°¸ê³  ê¸°ì‚¬")
    lines = ref_part.split('\n')
    formatted_lines = []
    for line in lines:
        if "URL:" in line:
            url_parts = line.split("URL:")
            if len(url_parts) > 1:
                url = url_parts[1].strip()
                formatted_lines.append(f"- URL: <a href='{url}' target='_blank'>{url}</a>")
        else:
            formatted_lines.append(f"- {line}")
    st.markdown('<br>'.join(formatted_lines), unsafe_allow_html=True)

def display_guide_section(guide_part):
    """
    ì‹ ì…ì‚¬ì› ê°€ì´ë“œ ì„¹ì…˜ í‘œì‹œ.
    """
    st.markdown("#### ğŸ¯ ì‹ ì…ì‚¬ì› ê°€ì´ë“œ")
    st.markdown(f"""
    <div style='background-color: #e8f4f9; padding: 20px; border-radius: 10px;'>
        {guide_part}
    </div>
    """, unsafe_allow_html=True)

def display_speech_section(speech_part):
    """
    ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€ ì„¹ì…˜ í‘œì‹œ ë° TTS ì¶œë ¥.
    """
    bot_image_path = os.path.join(ASSETS_DIR, 'bot_character.png')
    st.markdown(f"""
    <div style="display: flex; align-items: center; margin-bottom: 10px;">
        <img src="data:image/png;base64,{get_image_as_base64(bot_image_path)}" 
            alt="Bot Icon" 
            style="width: 30px; height: 30px; margin-right: 10px; border-radius: 50%;">
        <h3 style="margin: 0; display: inline;">AIë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€</h3>
    </div>
    <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px;">
        {speech_part}
    </div>
    """, unsafe_allow_html=True)

    if st.session_state.tts_enabled and 'audio_played' not in st.session_state:
        st.session_state.search_system.speak_result(speech_part)
        st.session_state.audio_played = True

def save_analysis_result(result, ref_part, guide_part, speech_part, query=None):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥"""
    formatted_result = "### ğŸ“Š ë¶„ì„ ê²°ê³¼\n\n"
    if ref_part:
        formatted_result += f"#### ğŸ“° ì°¸ê³  ê¸°ì‚¬\n{ref_part}\n\n"
    if guide_part:
        formatted_result += f"#### ğŸ¯ ì‹ ì…ì‚¬ì› ê°€ì´ë“œ\n{guide_part}\n\n"
    if speech_part:
        formatted_result += f"#### ğŸ’¬ ë¬¸ë™ê¶Œ ì‚¬ì¥ë‹˜ ë§ì”€\n{speech_part}"

    st.session_state.search_history.append({
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'query': query,  # query íŒŒë¼ë¯¸í„° ì‚¬ìš©
        'result': formatted_result
    })
    save_message(formatted_result, "ai")

        
def main():
    initialize_session_state()
    create_sidebar_with_text_analysis()
    
    # ê¸°ì¡´ ëŒ€í™” ì´ë ¥ í‘œì‹œ
    paint_history()

    if st.session_state.analysis_mode:
        # ë¶„ì„ ëª¨ë“œ ì²˜ë¦¬
        handle_analysis_mode()
    else:
        # ì¼ë°˜ ëª¨ë“œ ì²˜ë¦¬
        handle_regular_mode()
            
def handle_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ UI ì²˜ë¦¬"""
    st.markdown("---")
    st.markdown("### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV ë˜ëŠ” XLSX)", 
        type=["csv", "xlsx"],
        key="file_uploader_analysis"
    )
    if uploaded_file:
        process_uploaded_file(uploaded_file)
        

def handle_analysis_mode():
    """ë¶„ì„ ëª¨ë“œ UI ë° ë¡œì§ ì²˜ë¦¬"""
    st.markdown("---")
    st.markdown("### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV ë˜ëŠ” XLSX)", 
        type=["csv", "xlsx"],
        key="file_uploader_analysis"
    )

    if uploaded_file:
        file_analysis_result = analyze_uploaded_file(uploaded_file)
        if file_analysis_result:
            text_data, df = file_analysis_result
            st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state.file_data = text_data
            st.session_state.file_df = df

    # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì±„íŒ… ì…ë ¥ í‘œì‹œ
    if st.session_state.get("file_data") is not None:
        query = st.chat_input(
            "íŒŒì¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”",
            key="chat_input_analysis"
        )
        if query:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            send_message(query, "human")
            
            # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = analyze_text_with_context(
                    query,
                    st.session_state.file_data,
                    st.session_state.messages,
                    st.session_state.search_system
                )

            # ìš”ì²­ëœ ë¶„ì„ ì¢…ë¥˜ íŒŒì•…
            requested_analysis = determine_requested_analysis(query)

            # AI ì‘ë‹µ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ
            with st.chat_message("ai", avatar="static/bot_character.png"):
                if result:
                    if result["query_type"] == "data_analysis":
                        if "analysis" in result and result["analysis"]:
                            display_analysis_results(result["analysis"], requested_analysis)
                        else:
                            st.markdown("### ë‹µë³€")
                            st.markdown(result["answer"])
                            st.warning("ë¶„ì„ ê²°ê³¼ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.markdown("### ë‹µë³€")
                        st.markdown(result["answer"])
                        if "key_points" in result:
                            st.markdown("### ì£¼ìš” í¬ì¸íŠ¸")
                            for point in result["key_points"]:
                                st.markdown(f"- {point}")
                            
                if result:
                    # ê²°ê³¼ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥
                    # ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ result['answer']ì™€ result['analysis']ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
                    message_content = {
                        "answer": result.get("answer", ""),
                        "analysis": result.get("analysis", {})
                    }
                    save_message(message_content, "ai", "analysis")


def determine_requested_analysis(question: str) -> List[str]:
    """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì›í•˜ëŠ” ë¶„ì„ ì¢…ë¥˜ë¥¼ ë°˜í™˜"""
    analysis_types = []
    if any(word in question for word in ['í‚¤ì›Œë“œ', 'ì›Œë“œ í´ë¼ìš°ë“œ', 'ë‹¨ì–´', 'ë¹ˆë„']):
        analysis_types.append('keyword_frequency')
    if any(word in question for word in ['ê¸ì •', 'ë¶€ì •', 'ê°ì •', 'ê°ì„±']):
        analysis_types.append('sentiment_analysis')
    if any(word in question for word in ['ì¹´í…Œê³ ë¦¬', 'ì£¼ì œ', 'í† í”½', 'ë¶„ë¥˜']):
        analysis_types.append('topic_distribution')
    # ë¶„ì„ ì¢…ë¥˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë‘ í¬í•¨
    if not analysis_types:
        analysis_types = ['keyword_frequency', 'sentiment_analysis', 'topic_distribution']
    return analysis_types


def process_analysis_query(query):
    """ë¶„ì„ ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬"""
    send_message(query, "human")
    with st.spinner("ë¶„ì„ ì¤‘..."):
        result = analyze_text_with_context(
            text_query=query,
            file_data=st.session_state.file_data,
            chat_history=st.session_state.messages,
            search_system=st.session_state.search_system
        )
        with st.chat_message("ai", avatar="static/bot_character.png"):
            display_combined_analysis(result)
        save_message(result, "ai", "analysis")

def process_regular_query(query):
    """ì¼ë°˜ ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬"""
    send_message(query, "human")  # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    
    progress_bar = st.progress(0)
    with st.chat_message("ai", avatar="static/bot_character.png"):
        process_regular_chat(query, progress_bar)  

def handle_regular_mode():
    """ì¼ë°˜ ëª¨ë“œ UI ë° ë¡œì§ ì²˜ë¦¬"""
    query = st.chat_input(
    "ê¶ê¸ˆí•œ ì‚¬í•­ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”",
    key="chat_input_regular_mode"  # ê³ ìœ í•œ í‚¤ ì‚¬ìš©
    )

    if query:
        process_regular_query(query)

if __name__ == "__main__":
    main()